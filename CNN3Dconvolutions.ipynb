{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLNGD_MDyCLN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORtG94jlAuQI"
      },
      "outputs": [],
      "source": [
        "#path_post_enc = '/content/drive/Othercomputers/My Laptop/post_enc_frames'\n",
        "path_post_enc = '/content/drive/MyDrive/post_enc_frames2'\n",
        "path_pre_enc = '/content/drive/Othercomputers/My Laptop/pre_enc_frames'\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s-pi3-_CDV2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.layers import (Dense, Concatenate, Add, ReLU, Input, GlobalAveragePooling2D, Activation,\n",
        "                                     Conv1D, Multiply, Permute, Conv3D)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import CSVLogger\n",
        "from collections import deque\n",
        "import gc\n",
        "import copy\n",
        "import random\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "\n",
        "root = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AlTJJasUYWH"
      },
      "outputs": [],
      "source": [
        "folders_post = sorted(os.listdir(path_post_enc))\n",
        "folders_pre = sorted(os.listdir(path_pre_enc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDPetEwRAjAY"
      },
      "outputs": [],
      "source": [
        "def get_folder_indices(start_index, batch_size, frame_num=128):\n",
        "    folder_idx = start_index\n",
        "    indices = deque()\n",
        "\n",
        "    while len(indices) != batch_size:\n",
        "        os.chdir(os.path.join(path_post_enc, folders_post[folder_idx]))\n",
        "        files = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "        if len(files) >= frame_num:\n",
        "            indices.append(folder_idx)\n",
        "        folder_idx += 1\n",
        "\n",
        "    os.chdir(root)\n",
        "\n",
        "    return indices, folder_idx\n",
        "\n",
        "def data_generator(start_index, batch_size=batch_size):\n",
        "    indices, start_index = get_folder_indices(start_index=start_index, batch_size=batch_size, frame_num=128)\n",
        "    indices_copy = copy.deepcopy(indices)\n",
        "\n",
        "    X = np.empty(shape=(batch_size, 128, 256, 256, 1), dtype=\"float32\")\n",
        "    y = np.empty(shape=(batch_size, 128, 256, 256, 1), dtype=\"float32\")\n",
        "\n",
        "    # post enc\n",
        "    m = 0\n",
        "    while len(indices) > 0:\n",
        "        os.chdir(os.path.join(path_post_enc, folders_post[indices.popleft()]))\n",
        "        files = os.listdir(os.getcwd())\n",
        "        for i, file in enumerate(files):\n",
        "            if i < 128:\n",
        "                with open(file, 'rb') as yuv_file:\n",
        "                    X[m][i] = np.frombuffer(yuv_file.read(256 * 256), dtype=np.uint8).reshape((256, 256, 1))\n",
        "        m += 1\n",
        "\n",
        "    # pre enc\n",
        "    m = 0\n",
        "    while len(indices_copy) > 0:\n",
        "        os.chdir(os.path.join(path_pre_enc, folders_pre[indices_copy.popleft()]))\n",
        "        files = os.listdir(os.getcwd())\n",
        "        for i, file in enumerate(files):\n",
        "            if i < 128:\n",
        "                with open(file, 'rb') as yuv_file:\n",
        "                    y[m][i] = np.frombuffer(yuv_file.read(256 * 256), dtype=np.uint8).reshape((256, 256, 1))\n",
        "        m += 1\n",
        "\n",
        "    os.chdir(root)\n",
        "\n",
        "    return X / 255.0, y / 255.0, start_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRf2UyJIAtMR"
      },
      "outputs": [],
      "source": [
        "def dc_block(input):\n",
        "    x = Conv3D(filters=4, kernel_size=3, strides=1, padding='same')(input)\n",
        "\n",
        "    x1 = Dense(6, activation='relu')(x)\n",
        "    x1 = Conv3D(filters=6, kernel_size=3, strides=1,\n",
        "                padding='same', activation='relu')(x1)\n",
        "\n",
        "    x2 = Dense(8, activation='relu')(x1)\n",
        "    x2 = Dense(8, activation='relu')(x2)\n",
        "    x2 = Conv3D(filters=8, kernel_size=3, strides=1,\n",
        "                padding='same', activation='relu')(x2)\n",
        "\n",
        "    x3 = Dense(10, activation='relu')(x2)\n",
        "    x3 = Dense(10, activation='relu')(x3)\n",
        "    x3 = Dense(10, activation='relu')(x3)\n",
        "    x3 = Conv3D(filters=10, kernel_size=3, strides=1,\n",
        "                padding='same', activation='relu')(x3)\n",
        "\n",
        "    x4 = Dense(12, activation='relu')(x3)\n",
        "    x4 = Dense(12, activation='relu')(x4)\n",
        "    x4 = Dense(12, activation='relu')(x4)\n",
        "    x4 = Dense(12, activation='relu')(x4)\n",
        "    x4 = Conv3D(filters=12, kernel_size=3, strides=1,\n",
        "                padding='same', activation='relu')(x4)\n",
        "\n",
        "    x5 = Dense(12, activation='relu')(x4)\n",
        "    x5 = Concatenate()([Dense(4)(input), x5])\n",
        "    x5 = Conv3D(filters=8, kernel_size=3, strides=1,\n",
        "                padding='same', activation='relu')(x5)\n",
        "\n",
        "    x6 = Add()([x5, input])\n",
        "    out = Conv3D(filters=8, kernel_size=3, strides=1,\n",
        "                 padding='same', activation='relu')(x6)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def dcr_net(input_shape=(None, None, None, 1), filters=8,\n",
        "            name='DCRN_model'):  # ORIGINAL 64 filters!!!\n",
        "    lr_image = Input(shape=input_shape, name='input')\n",
        "    x_start = Conv3D(filters, kernel_size=3, strides=1,\n",
        "                     padding='same')(lr_image)\n",
        "    x_start = ReLU()(x_start)\n",
        "    x = dc_block(x_start)\n",
        "    x1 = dc_block(x)\n",
        "    x2 = dc_block(x1)\n",
        "    x3 = Concatenate()([Dense(8)(x_start), x, x1, x2])\n",
        "    x4 = Conv3D(filters, kernel_size=3, strides=1, padding='same')(x3)\n",
        "    x4 = ReLU()(x4)\n",
        "    # x5 = cab(x4)\n",
        "    x5 = Add()([x4, x_start])\n",
        "    out = Conv3D(1, kernel_size=3, strides=1, padding='same',\n",
        "                 dtype='float64')(x5)\n",
        "    return tf.keras.Model(inputs=lr_image, outputs=out, name=name)\n",
        "\n",
        "\n",
        "def cab(input):\n",
        "    x = GlobalAveragePooling2D()(input)\n",
        "    x = Permute((2, 1))(x)  # Act on channel axis\n",
        "    x = Conv1D()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv1D()(x)\n",
        "    x = Activation('sigma')(x)\n",
        "    x = Permute((2, 1))(x)  # Restore original channel axis\n",
        "    out = Multiply()([x, input])\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcFfkPq4Avyu"
      },
      "outputs": [],
      "source": [
        "Model = dcr_net()\n",
        "\n",
        "csv_logger = CSVLogger('/content/drive/MyDrive/log.csv', append=True, separator=';')\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/3Dmodel2_checkpoint.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='loss',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    save_freq=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO3s0X3kBEyW"
      },
      "outputs": [],
      "source": [
        "Model = tf.keras.models.load_model(checkpoint_filepath) # ÇOK DİKKAT ET BU KAPALI BUNUN KAPALI OLMASI GERKEN DURUMLAR OLABİLİR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4AZzpTSBLBG"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
        "Model.compile(optimizer=optimizer, loss='mse', metrics=[\"mse\", \"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-vI1SNBExOD"
      },
      "outputs": [],
      "source": [
        "# epochs = 460 (0.8 test size)\n",
        "st_ix = 0\n",
        "epochs = 11\n",
        "file_path = '/content/drive/MyDrive/devam_indisi.txt'\n",
        "kac_epoch = '/content/drive/MyDrive/d_kac_epoch.txt'\n",
        "\n",
        "for i in range(epochs):\n",
        "    while True:\n",
        "        with open(file_path, 'r') as file:\n",
        "            st_ix = int(file.read())\n",
        "\n",
        "        if st_ix >= 456:\n",
        "            with open(file_path, 'w') as file:\n",
        "                file.write(\"0\")\n",
        "            with open(kac_epoch, 'r') as file:\n",
        "                a = file.read()\n",
        "                a = int(a)\n",
        "            with open(kac_epoch, 'w') as file:\n",
        "                a += 1\n",
        "                file.write(f\"{a}\")\n",
        "            break\n",
        "\n",
        "        X_train, y_train, st_ix = data_generator(st_ix, 8)\n",
        "\n",
        "        rand1 = random.randint(0, 128)\n",
        "        Model.fit(\n",
        "            x=X_train[:, :, rand1:rand1+128, rand1:rand1+128],\n",
        "            y=y_train[:, :, rand1:rand1+128, rand1:rand1+128],\n",
        "            epochs=1,\n",
        "            batch_size=1,\n",
        "            shuffle=True,\n",
        "            callbacks=[model_checkpoint_callback]\n",
        "        )\n",
        "\n",
        "\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(f\"{st_ix}\")\n",
        "\n",
        "        gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMzk2D1xBR2Z"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "with open('/content/drive/MyDrive/devam_indisi.txt', 'r') as file:\n",
        "    st_ix = int(file.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz5Jx7MtrU5d"
      },
      "outputs": [],
      "source": [
        "pred_loss_list = []\n",
        "x_loss_list = []\n",
        "pred_psnr_list = []\n",
        "x_psnr_list = []\n",
        "ssim_pred_list = []\n",
        "ssim_x_list = []\n",
        "batch_size = 8\n",
        "coef=5\n",
        "\n",
        "predictions = np.empty(shape=(batch_size, 128, 256, 256, 1), dtype=\"float32\")\n",
        "for k in range(464, 565, 8):\n",
        "  X_val, y_val, _ = data_generator(start_index=k, batch_size=batch_size)\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      predictions[:, :, i*128:(i+1)*128, j*128:(j+1)*128] = Model.predict(X_val[:, :, i*128:(i+1)*128, j*128:(j+1)*128])\n",
        "  pred_loss = np.sum(np.square(y_val - predictions))/(batch_size*128)\n",
        "  x_loss = np.sum(np.square(X_val - y_val))/(batch_size*128)\n",
        "  pred_psnr = 20*np.log10(255/np.sqrt(pred_loss))\n",
        "  x_psnr = 20*np.log10(255/np.sqrt(x_loss))\n",
        "\n",
        "  sum_pred_i = 0\n",
        "  sum_x_i = 0\n",
        "  for i in range(X_val.shape[0]):\n",
        "    sum_pred_fr = 0\n",
        "    sum_x_fr = 0\n",
        "    for j in range(X_val.shape[1]):\n",
        "      ssim_pred, diff_pred = ssim(y_val[i][j], predictions[i][j], full=True, channel_axis=-1)\n",
        "      ssim_x, diff_x = ssim(y_val[i][j], X_val[i][j], full=True, channel_axis=-1)\n",
        "\n",
        "      sum_pred_fr += diff_pred\n",
        "      sum_x_fr += diff_x\n",
        "\n",
        "    sum_pred_i += sum_pred_fr/X_val.shape[1]\n",
        "    sum_x_i += sum_x_fr/X_val.shape[1]\n",
        "\n",
        "  ssim_pred_list.append(sum_pred_i/X_val.shape[0])\n",
        "  ssim_x_list.append(sum_x_i/X_val.shape[0])\n",
        "\n",
        "  print(f\"pred ssim: {ssim_pred}\")\n",
        "  print(f\"x ssim: {ssim_x}\")\n",
        "\n",
        "  ssim_pred, diff_pred = ssim(y_val, predictions, full=True)\n",
        "  ssim_x, diff_x = ssim(y_val, X_val, full=True)\n",
        "\n",
        "  print(f\"pred loss: {pred_loss} PSNR:{pred_psnr}\")\n",
        "  print(f\"x_loss: {x_loss} PSNR:{x_psnr}\")\n",
        "  pred_loss_list.append(pred_loss)\n",
        "  x_loss_list.append(x_loss)\n",
        "  pred_psnr_list.append(pred_psnr)\n",
        "  x_psnr_list.append(x_psnr)\n",
        "\n",
        "\n",
        "print(f\"Pred MSE average {np.average(np.array(pred_loss_list))}\")\n",
        "print(f\"X MSE average {np.average(np.array(x_loss_list))}\")\n",
        "print(f\"Pred PSNR average {np.average(np.array(pred_psnr_list))}\")\n",
        "print(f\"X PSNR average {np.average(np.array(x_psnr_list))}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}